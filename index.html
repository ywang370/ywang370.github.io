<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Yilin Wang</title>

    <meta name="author" content="Yilin Wang">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Yilin Wang
                </p>
                <p>I'm a research scientist at <a href="https://www.adobe.com/">Adobe</a> in San Jose, where I in a team mostly works for computer vision research for Adobe Imaging proucts. </a>.
                </p>
                <p>
                  At Adobe I've worked on <a href="https://firefly.adobe.com"> Instruction based Image Editing</a>,  <a href="https://theblog.adobe.com/photoshop-reimagined-for-ipad-introducing-select-subject/">Select Subject</a>, <a href="https://photoshopcafe.com/use-amazing-new-object-finder-photoshop-2022-instant-automatic-selections-objects-image/">Photoshop Object finder(14% MAU!)</a>, <a href="https://helpx.adobe.com/photoshop/how-to/selection-tools-basics.html">Photoshop Selection Improvement (increase 4%  MAU)</a>, and <a href="https://theblog.adobe.com/creativity-gets-an-ai-powered-boost-in-adobes-latest-remix/">Style Transfer</a>. I did my PhD at <a href="https://www.asu.edu/">Arizona State University</a>, where I was advised by <a href="https://search.asu.edu/profile/747601">Baoxin Li</a>. I am the core researcher for 8 tech transfer for Adobe Products  such as Photoshop, Lightroom and Stardust.
                </p>
                <p style="text-align:center">
                  <a href="mailto:wangyilin930@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=fYqdLx4AAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                   <a href="https://www.linkedin.com/in/yilinasu/">Linkedin</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="image/Wang-Yilin-8013b_meitu_1.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="image/Wang-Yilin-8013b_meitu_1.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Highlighted Research</h2>
                <p>
                  I'm interested in computer vision, machine learning, computer vision, and image processing. Most of my research is about images understanding and editing. Representative papers are <span class="highlight">highlighted</span>. See the <a href="https://scholar.google.com/citations?user=fYqdLx4AAAAJ&hl=en">full list</a>
                </p>
              </td>
            </tr>
  </tbody></table>
  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


      <tr onmouseout="swapanything_stop()" onmouseover="swapanything_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='swapanything_image'>
              <img src='images/swapanything_after.png' width="200",height="160"></div>
              <img src='images/swapanything_before.png' width="200",height="160">
          </div>
          <script type="text/javascript">
            function swapanything_start() {
              document.getElementById('swapanything_image').style.opacity = "1";
            }

            function swapanything_stop() {
              document.getElementById('swapanything_image').style.opacity = "0";
            }
            swapanything_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="http://arxiv.org/abs/2404.05717">
            <span class="papertitle">SwapAnything: Enabling Arbitrary Object Swapping in Personalized Visual Editing</span>
          </a>
          <br>
          <a href="https://g-jing.github.io/">Jing Gu</a>,
          <strong>Yilin Wang</strong>
          <a href="http://nxzhao.com//">Nanxuan Zhao</a>,
          <a href="https://tsujuifu.github.io/">Tsu-Jui Fu</a>,
          <a href="https://wxiong.me/">Wei Xiong</a>,
          <a href="https://qliu24.github.io/">Qing Liu</a>,
          <a href="https://zzutk.github.io/">Zhifei Zhang</a>,
          <a href="https://sites.google.com/site/hezhangsprinter/">He Zhang</a>,
          <a href="https://cs-people.bu.edu/jmzhang/">Jianming Zhang</a>,
          <a href="https://polaris79.wixsite.com/hjung">HyunJoon Jung</a>,
          <a href="https://eric-xw.github.io/">Xin Eric Wang</a>
          <br>
          <a href="https://swap-anything.github.io/">project page</a> /
          <a href="http://arxiv.org/abs/2404.05717">paper</a> /

          <em>Arxiv<em>, 2024
          <br>
          <p></p>
          <p>
          A method for personalized subject driven image editing.
          </p>
        </td>
      </tr>

      <tr onmouseout="unihuman_stop()" onmouseover="unihuman_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">

          <div id='unihuman_still'><img src="images/unihuman.png" width="160", height="80"></div>
          <script type="text/javascript">
            function amodal_start() {
              document.getElementById('unihuman_still').style.display = 'inline';
            }

            function amodal_stop() {
              document.getElementById('unihuman_still').style.display = 'inline';
            }
            amodal_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://arxiv.org/abs/2312.14985">
            <span class="papertitle">UniHuman: A Unified Model for Editing Human Images in the Wild.</span>
          </a>
          <br>
        <a href=>Nannan Li</a>,
        <a href="https://scholar.google.com/citations?user=1ytghtEAAAAJ&hl=en">Qing Liu</a>,
        <a href="https://krsingh.cs.ucdavis.edu/">Krishna Kumar Singh</a>,
            <strong>Yilin Wang</strong>
        <a href="https://cs-people.bu.edu/jmzhang/">Jianming Zhang</a>,
        <a >Bryan A. Plummer</a>,
        <a href="https://sites.google.com/site/zhelin625/">Zhe Lin</a>,

          <br>
          <em>CVPR</em>, 2024
          <br>
          <p> Human editing via diffusion.</p>
        </td>
      </tr>

      <tr onmouseout="amodal_stop()" onmouseover="amodal_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">

          <div id='amodal_still'><img src="images/amodal.png" width="160", height="130"></div>
          <script type="text/javascript">
            function amodal_start() {
              document.getElementById('amodal_still').style.display = 'inline';
            }

            function amodal_stop() {
              document.getElementById('amodal_still').style.display = 'inline';
            }
            amodal_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a >
            <span class="papertitle">Amodal Scene Analysis via Holistic Occlusion Relation Inference and Generative Mask Completion</span>
          </a>
          <br>
        <a href=>Bowen Zhang</a>,
        <a href="https://sites.google.com/site/hezhangsprinter/">Qing Liu</a>,
        <a href="https://cs-people.bu.edu/jmzhang/">Jianming Zhang</a>,
        <strong>Yilin Wang</strong>
        <a >Akide Liu</a>,
        <a href="https://sites.google.com/site/zhelin625/">Zhe Lin</a>,
        <a href="https://scholar.google.com/citations?user=ksQ4JnQAAAAJ&hl=zh-CN">Yifan Liu</a>,

          <br>
          <em>AAAI (oral)</em>, 2024
          <br>
          <a >project page</a> /
          <a >paper</a>

          <p> Amodal Segmentation considers mutual occulusion.</p>
        </td>
      </tr>


      <tr onmouseout="photoswap_stop()" onmouseover="photoswap_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='photoswap_image'>
              <img src='images/photoswap_after.png' width="160"></div>
            <img src='images/photoswap_before.png' width="160">
          </div>
          <script type="text/javascript">
            function photoswap_start() {
              document.getElementById('photoswap_image').style.opacity = "1";
            }

            function photoswap_stop() {
              document.getElementById('photoswap_image').style.opacity = "0";
            }
            photoswap_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://arxiv.org/abs/2305.18286">
            <span class="papertitle">PHOTOSWAP: Personalized Subject Swapping in Images</span>
          </a>
          <br>
          <a href="https://g-jing.github.io/">Jing Gu</a>,
          <strong>Yilin Wang</strong>
          <a href="http://nxzhao.com//">Nanxuan Zhao</a>,
          <a href="https://tsujuifu.github.io/">Tsu-Jui Fu</a>,
          <a href="https://wxiong.me/">Wei Xiong</a>,
          <a href="https://qliu24.github.io/">Qing Liu</a>,
          <a href="https://zzutk.github.io/">Zhifei Zhang</a>,
          <a href="https://sites.google.com/site/hezhangsprinter/">He Zhang</a>,
          <a href="https://cs-people.bu.edu/jmzhang/">Jianming Zhang</a>,
          <a href="https://polaris79.wixsite.com/hjung">HyunJoon Jung</a>,
          <a href="https://eric-xw.github.io/">Xin Eric Wang</a>
          <br>
          <a href="https://photoswap.github.io/">project page</a> /
          <a href="https://arxiv.org/pdf/2305.18286.pdf">paper</a> /

          <em>NeurIPS<em>, 2023
          <br>
          <p></p>
          <p>
          A method for personalized subject driven image editing.
          </p>
        </td>
      </tr>



      <tr onmouseout="LightPainter_stop()" onmouseover="LightPainter_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">

          <div id='LightPainter_still'><img src="images/lightpainter.png" width="160", height="160"></div>
          <script type="text/javascript">
            function LightPainter_start() {
              document.getElementById('LightPainter_still').style.display = 'inline';
            }

            function LightPainter_stop() {
              document.getElementById('LightPainter_still').style.display = 'inline';
            }
            LightPainter_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://arxiv.org/abs/2303.12950">
            <span class="papertitle">LightPainter: Interactive Portrait Relighting with Freehand Scribble</span>
          </a>
          <br>
        <a href="https://yiqunmei.net/">Yiqun Mei</a>,
        <a href="https://sites.google.com/site/hezhangsprinter/">He Zhang</a>,
        <a href="https://ceciliavision.github.io/">Xuaner Zhang</a>,
        <a href="https://cs-people.bu.edu/jmzhang/">Jianming Zhang</a>,
        <a href="https://zhixinshu.github.io/">Zhixin Shu</a>,
        <strong>Yilin Wang</strong>
        <a href="https://scholar.google.com/citations?user=8l3bFYYAAAAJ&hl=en">Zijun Wei</a>,
        <a>Yan Shi</a>,
        <a href="https://polaris79.wixsite.com/hjung">HyunJoon Jung</a>,
        <a href="https://scholar.google.com/citations?user=AkEXTbIAAAAJ&hl=en">Vishal M. Patel</a>,

          <br>
          <em>CVPR</em>, 2023
          <br>
          <a href="https://yiqunmei.net/lightpt/">project page</a> /
          <a href="https://yiqunmei.net/lightpt/resources/CVPR2023_LightPainter.pdf">paper</a>

          <p>A scribble-based relighting system that allows users to interactively manipulate portrait lighting effect with ease.</p>
        </td>
      </tr>

      <tr onmouseout="interactive_stop()" onmouseover="interactive_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">

          <div id='interactive_still'><img src="images/interactive.png" width="160", height="160"></div>
          <script type="text/javascript">
            function interactive_start() {
              document.getElementById('interactive_still').style.display = 'inline';
            }

            function interactive_stop() {
              document.getElementById('interactive_still').style.display = 'inline';
            }
            interactive_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://arxiv.org/abs/2203.08216">
            <span class="papertitle">Interactive Portrait Harmonization</span>
          </a>
          <br>
        <a href="https://jeya-maria-jose.github.io/research/">Jeya Maria Jose Valanarasu</a>,
        <a href="https://sites.google.com/site/hezhangsprinter/">He Zhang</a>,
        <a href="https://cs-people.bu.edu/jmzhang/">Jianming Zhang</a>,
        <strong>Yilin Wang</strong>,
        <a href="https://research.adobe.com/person/zhe-lin/">Zhe Lin</a>,
        <a href="https://www.linkedin.com/in/yinglan-ma/">Yinglan Ma</a>,
        <a href="https://scholar.google.com/citations?user=8l3bFYYAAAAJ&hl=en">Zijun Wei</a>,
        <a href="http://www.kalyans.org/"> Kalyan Sunkavalli</a>
        <a href="https://scholar.google.com/citations?user=AkEXTbIAAAAJ&hl=en">Vishal M. Patel</a>
        <br>
        <em>ICLR</em>, 2023
        <br>
        <a href="https://jeya-maria-jose.github.io/IPH-web/">project page</a> /
        <a href="https://arxiv.org/abs/2203.08216">paper</a>

          <p>Interactive Harmonization for portrait photo.</p>
        </td>
      </tr>

     <tr onmouseout="lvt_stop()" onmouseover="lvt_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">

          <div id='lvt_still'><img src="images/lvt.png" width="190", height="160"></div>
          <script type="text/javascript">
            function lvt_start() {
              document.getElementById('lvt_still').style.display = 'inline';
            }

            function lvt_stop() {
              document.getElementById('lvt_still').style.display = 'inline';
            }
            lvt_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://arxiv.org/abs/2112.10809">
            <span class="papertitle">Lite Vision Transformer with Enhanced Self-Attention</span>
          </a>
          <br>
        <a href="https://www.chenglinyang.com/">Chenglin Yang</a>,
        <strong>Yilin Wang</strong>,
        <a href="https://cs-people.bu.edu/jmzhang/">Jianming Zhang</a>,
        <a href="https://sites.google.com/site/hezhangsprinter/">He Zhang</a>,
        <a href="https://cs-people.bu.edu/jmzhang/">Jianming Zhang</a>,
        <a href="https://scholar.google.com/citations?user=8l3bFYYAAAAJ&hl=en">Zijun Wei</a>,
        <a href="https://research.adobe.com/person/zhe-lin/">Zhe Lin</a>,
        <a href="https://www.cs.jhu.edu/~ayuille/">Alan Yuille</a>
        <br>
        <em>CVPR</em>, 2022
        <br>
        <a href="https://www.chenglinyang.com/publication/lvt/">project page</a> /
        <a href="https://arxiv.org/abs/2112.10809">paper</a>

          <p> light-weight vision transformer models for vision tasks.</p>
        </td>
      </tr>

       <tr onmouseout="ssh_stop()" onmouseover="ssh_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">

          <div id='ssh_still'><img src="images/ssh.png" width="190", height="160"></div>
          <script type="text/javascript">
            function lvt_start() {
              document.getElementById('ssh_still').style.display = 'inline';
            }

            function lvt_stop() {
              document.getElementById('ssh_still').style.display = 'inline';
            }
            lvt_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://arxiv.org/abs/2108.06805">
            <span class="papertitle">SSH: A Self-Supervised Framework for Image Harmonization</span>
          </a>
          <br>
        <a href="https://www.chenglinyang.com/">Yifan Jiang</a>,
        <a href="https://sites.google.com/site/hezhangsprinter/">He Zhang</a>,
        <a href="https://cs-people.bu.edu/jmzhang/">Jianming Zhang</a>,
        <strong>Yilin Wang</strong>,
        <a href="https://research.adobe.com/person/zhe-lin/">Zhe Lin</a>,
        <a href="http://www.kalyans.org/">Kalyan Sunkavalli</a>,
        <a >Simon Chen</a>,
        <a href="https://scholar.google.com/citations?user=aFrtZOIAAAAJ&hl=en">Sohrab Amirghodsi</a>,
        <a href="https://blog.adobe.com/en/publish/2017/08/02/women-in-technology-sarah-kong">Sarah Kong</a>,
        <a href="https://www.ece.utexas.edu/people/faculty/atlas-wang">Zhangyang Wang</a>,
        <br>
        <em>ICCV</em>, 2021
        <br>
        <a href="https://arxiv.org/abs/2108.06805">paper</a>

          <p> Image Harmonization based on self-supervised learning</p>
        </td>
      </tr>

      <tr onmouseout="mgm_stop()" onmouseover="mgm_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">

          <div id='mgm_still'><img src="images/yu2020mask.png" width="190", height="100"></div>
          <script type="text/javascript">
            function mgm_start() {
              document.getElementById('mgm_still').style.display = 'inline';
            }

            function mgm_stop() {
              document.getElementById('mgm_still').style.display = 'inline';
            }
            mgm_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://arxiv.org/pdf/2012.06722.pdf">
            <span class="papertitle">Mask Guided Matting via Progressive Refinement Network</span>
          </a>
          <br>
        <a href="https://yucornetto.github.io/">Qihang Yu</a>,
        <a href="https://cs-people.bu.edu/jmzhang/">Jianming Zhang</a>,
        <a href="https://sites.google.com/site/hezhangsprinter/">He Zhang</a>,
        <strong>Yilin Wang</strong>,
        <a href="https://research.adobe.com/person/zhe-lin/">Zhe Lin</a>,
        <a href="https://sites.google.com/view/ningxu/">Ning Xu</a>,
        <a href="https://yutongbai.com/">Yutong  Bai</a>,
        <a href="https://www.cs.jhu.edu/~ayuille/">Alan Yuille</a>
        <br>
        <em>CVPR</em>, 2021
        <br>
        <a href="https://github.com/yucornetto/MGMatting">project page</a> /
        <a href="https://arxiv.org/pdf/2012.06722.pdf">paper</a>

          <p> Mask Guided Image Matting</p>
        </td>
      </tr>

      <tr onmouseout="mct_stop()" onmouseover="mct_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">

          <div id='mct_still'><img src="images/mct.png" width="160", height="100"></div>
          <script type="text/javascript">
            function mct_start() {
              document.getElementById('mct_still').style.display = 'inline';
            }

            function mct_stop() {
              document.getElementById('mct_still').style.display = 'inline';
            }
            mct_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Yuan_Multimodal_Contrastive_Training_for_Visual_Representation_Learning_CVPR_2021_paper.pdf">
            <span class="papertitle">Multimodal Contrastive Training for Visual Representation Learning</span>
          </a>
          <br>
        <a href="https://scholar.google.com/citations?user=EiD_2e0AAAAJ&hl=en">Xin Yuan</a>,
        <a href="https://sites.google.com/site/zhelin625/">Zhe Lin</a>,
        <a href="https://scholar.google.com.my/citations?user=e6u7GlQAAAAJ&hl=en">Jason Kuen</a>,
        <a href="https://cs-people.bu.edu/jmzhang/">Jianming Zhang</a>,
        <strong>Yilin Wang</strong>
        <a >Michael Maire</a>,
        <a >Ajinkya Kale</a>,
        <a >Baldo Faieta</a>,

          <br>
          <em>CVPR</em>, 2021
          <br>
          <a >project page</a> /
          <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Yuan_Multimodal_Contrastive_Training_for_Visual_Representation_Learning_CVPR_2021_paper.pdf">paper</a>

          <p> Intra- and inter-modal similarity preservation for multimodal representation learning.</p>
        </td>
      </tr>


  </tbody></table>





          
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Miscellanea</h2>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="20"><tbody>
            
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
              <td width="75%" valign="center">
                <a>Area Chair, ACM MM 2020</a>
          <br>
                <a >Area Chair, ACM MM 2021</a>
                  <br>
                <a >Committee, Adobe Fellowship</a>
                <br>
                <a >Reviewer of CVPR, ICCV, ECCV, ICML, NuriPS since 2017</a>
                  <br>
                <a >Arizona State Graduate Student Fellowship 2017</a>
                <br>
              </td>
            </tr>


            <tr>
              <td align="center" style="padding:20px;width:25%;vertical-align:middle">
                <h2>Past <br> Research Interns</h2>
              </td>
              <td width="75%" valign="middle">
                <a href="https://zhke.io/"> Zhanghan Ke</a>,
                <a href="https://cs-people.bu.edu/nnli/">Nannan Li</a>,
                <a href="https://yiqunmei.net/">Yiqun Mei </a>,
                <br>
                <a href="https://yulunzhang.com/"> Yulun Zhang</a>,
                <a href="https://shikun.io//">Shikun Liu</a>,
                <a href="https://www.chenglinyang.com/">Chenglin Yang</a>,
                <br>
                <a href="https://jeya-maria-jose.github.io/research/">Jeya Maria Jose Valanarasu</a>,
                <a href="https://shikun.io//">Kenan E Ak</a>,
                <a href="https://yucornetto.github.io/">Qihang Yu</a>,
                <br>
                <a href="https://scholar.google.com/citations?user=EiD_2e0AAAAJ&hl=en">Xin Yuan </a>,
               <a href="https://yifanjiang19.github.io/">Yifan Jiang</a>,
               <a href="https://g-jing.github.io/">Jing Gu</a>,
               <a href="https://scholar.google.com.hk/citations?user=Q88BI2QAAAAJ&hl=en">Zhibo Yang </a>
                <br>
              </td>
            </tr>

            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Copy the website template from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
